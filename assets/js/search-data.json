{
  
    
        "post0": {
            "title": "NGS Application-Variant Calling",
            "content": "Introduction . NGS 기계를 통해 얻은 raw data는 기본적으로 리눅스 시스템에서 처리된다. 이때 사용되는 툴킷은 대표적으로 broad institute에서 만든 GATK가 있다. 이번 노트에서는 NGS의 여러 응용(Application) 중 Variant calling에 대해 다룬다. 본 자료는 cornell university의 workshop자료를 기반으로 한다. . Variant Calling . &#51221;&#51032; . variant는 유전적변이를 의미한다. (네이버 사전) variant call은 genome 혹은 transcriptome에서 reference genome과 뉴클레오타이드 서열에 차이가 있는지를 살펴보는 것을 말한다. 즉, reference genome의 시퀀스와 대상 genome 시퀀스 상의 변화를 찾아낸다. 즉, SNP를 찾아낸다. . SNP란 인구 집단에서 1% 이상의 빈도로 존재하는 2개 이상의 대립 염기서열이 발생하는 위치를 말한다. 각 샘플의 Read data (D)로부터 샘플의 Genotype (T)을 알아내려면 Genotype이 나올 확률을 Bayesian rule을 이용하여 계산하게 된다. SNP 외에 염기서열 상의 insertion, deletion 등의 mutation도 찾아낸다. . Individual 1은 시퀀스를 하려는 특정한 사람의 DNA. 혹은 정상세포에서 얻은 DNA, Individual 2는 또 다른 사람의 DNA, Individual 3는 암 환자에게서 추출한 세포에서 얻은 DNA라고 가정해보자. 이렇게 서로 다른 세포에서 얻은 두 genome의 차이를 살펴, 암을 유발하는 사이트를 알아내려는 것이 목적이다. 보통 휴먼지놈은 30억 bp다. 이를 통째로 시퀀싱 하지 못하므로, 잘게 잘라낸다. 이를 통해 작은 read들을 NGS를 통해 얻어내고 그 결과들을 이어붙여 원래의 whole genome 시퀀스를 확보한다. 그 후에 상호 간의 시퀀스를 비교한다. 이러한 과정들은 사람이 직접 할 수 없으므로 프로그램에 맡긴다. NGS 기계에서 최종적으로 나오는 output은 FASTQ 포맷의 파일이며 그 예는 다음과 같다. FASTQ에 대해서는 후반부에 다룬다. . 이런 류의 파일을 모은 후, FASTQ 파일에 있는 데이터들에 대한 align을 수행하게 된다. 중첩된 것들은 따라가면서 전체 시퀀스를 어우르게 된다. . reference genome sequence는 휴먼 지놈 프로젝트를 통해 밝혀진, 이미 알려진 genome sequence다. 사람에 대한 reference sequence는 이미 존재하므로 이를 기반으로 FASTQ 파일로부터 align된 시퀀스들을 reference sequence로 맵핑한다. 이 과정에서 GATK가 사용된다. . GATK . NGS 기계를 통해 얻은 raw data는 GATK 툴킷으로 주로 처리된다. GATK 외에 SAMtools, glfTools, Atlas2가 있다. GATK는 Bayesian 모델을 이용하고, 알고리즘은 MapReduce를 이용하여 분산 처리가 가능하다는 장점이 있다. GATK는 java program으로 짜여져 있다. 휴먼 지놈 프로젝트는 2000년대에 완성되었다. 그 후, 1000 명에 대한 genome sequencing 즉, 1000 genome project가 진행되었고 현재는 종료된 상태다. 이때 발생한 패키지가 GATK다. 자바로 짜여진 프로그램이며, command-line의 툴이기 때문에 명령창에서 명령어를 입력해야 사용할 수 있다. 추가적으로 명령어 뒤의 옵션에 따라 다음의 일을 수행할 수 있다. . NGS data processing | variant discovery | variant filtering | genotyping | evaluation(평가 기능) | parallel processing on HPC clusters(병렬 처리 기능) | 병렬 처리 일반적인 소프트웨어는 하나의 CPU에 하나의 코어를 점유한다. 즉, 싱글 코어를 사용한다. 그러나 병렬 처리를 한다는 것은 여러 코어(또는 여러 쓰레드)를 점유하여 빠르게 처리하는 것을 말한다. 즉, 계산할 데이터를 나누어 각 CPU 코어에 계산을 맡긴다. 이때 CPU 내의 여러 코어를 사용할 수도 있고, 쓰레드를 사용할 수도 있다. GATK 실행 시, 명령 옵션을 통해 쓰레드 수를 지정할 수 있다. 그러나 단순히 쓰레드 수를 늘린다고 속도가 높아지는 것은 아니다. 즉, 쓰레드 수에 따라 선형적인 성능을 보장하지 않는다. 이는 오버헤드가 발생하기 때문이다. 일을 나누어주는 것 자체가 일이며, 분산시킨 작업의 결과를 취합하는 것 또한 CPU에겐 부담이다. 따라서 여러 코어, 여러 쓰레드를 쓰는 것이 선형적인 성능을 보장하지 않는다. 일반적으로 8~10개 정도가 적당하다. | . GATK에 대한 BEST practice는 다음의 사이트에서 참고할 수 있다; https://gatk.broadinstitute.org/hc/en-us . NGS data Analysis Pipeline . NGS 데이터를 처리하기 위한 일련의 과정을 파이프라인으로 정의할 수 있다. 각 과정에서는 서로 다른 소프트웨어가 쓰일 수 있으며 어떤 소프트웨어의 output이 검증 과정을 거친 후 다른 소프트웨어의 input이 된다. 즉, input으로 raw data를 주면 자동으로 다음 단계들을 알아서 실행하여 최종적으로 원하는 output이 나오도록 설계하는 것을 파이프라인이라고 한다. 일련의 작업들을 알아서 수행하는 매크로와도 같은 개념이다. 이렇게 파이프라인 만드는 것이 BI 회사들이 주로 하는 일이다. 파이썬, 쉘 스크립트 등을 이용하여 이러한 파이프라인을 구축할 수 있다. . A. Data Cleanup . . 먼저, NGS 기계로부터 raw reads를 받는다. 이 데이터는 fastq 포맷의 파일이다. | 그 다음엔 해당 파일 내의 데이터를 전처리한다. 불필요한 부분을 잘라내고, 필요한 부분만을 추려내는 과정이다 (실제 사용 예는 하단에 있음). 이렇게 처리된 데이터의 quality를 검증한 후, BWA 소프트웨어를 이용하여 Reference mapping을 수행한다. | Alignment(또는 Mapping)가 완료된 후에는 sorting을 수행한다. | sorting이 필요한 이유는 인덱싱 작업을 하기 위해서다. 데이터베이스 상에서 인덱싱 된 데이터일 경우 빠르게 검색 가능하기 때문이다. 이때 picard 소프트웨어가 쓰인다. 이는 다음 작업인 duplicate를 제거하는 작업을 빠르게 한다. | . duplicate를 체크하고, 제거한다. 과정 4까지는 Non-GATK 즉, GATK가 쓰이지 않는다. 과정 5, 6은 GATK가 쓰인다. | 그 후 indel realignment. 인설션, 딜리션 처리 후, | base recalibration을 수행 과정 6까지 끝나고 난 output: analysis-ready reads. 이로써 Variant Discovery를 위한 기본적인 준비는 끝이 났다. | pair of FASTQ files . 위 그림은 각 샘플에 대한 작업을 의미한다. 모든 과정에서, 샘플은 하나가 아닌 여러 샘플을 동시에 처리하는 경우가 대부분이다. 사람마다 genome은 다른데 reference sequence는 딱 하나다. 즉, 질병에 의한 varitaion 뿐만 아니라 사람 간의 variation도 존재한다. 우리의 목적이 무엇이냐에 따라 다르겠으나, (어떠한 genotype이 어떠한 phenotype을 나타내는지에 관심이 있는 경우도 있다.)주로 질병 치료, 진단 등이 목적이 된다 (돈이 되기 때문). 즉, 정상과 비정상간의 variant calling이 주 목적이다. 이때 사람 간의 variation은 무시해야 하므로, 통계적 유의미성 확보를 위해 굉장히 많은 샘플 이용해야 한다. 따라서 몇 백~몇 천 명의 샘플이 필요하다. 따라서 각 샘플은 동일한 파이프라인을 거치게 된다. . B. Variant Discovery . 처리한 것들을 묶어서 variant calling을 수행한다. 이를 통해 샘플 간 정상과 비정상간의 SNP를 알 수 있다 (몇 번 크로모솜의 어느 site에서 변이가 일어났는지, indel(insertion, deletion)이 일어났는지 등). Data Cleanup, Variant Discovery 과정까지가 bioinformatics의 영역이라고 할 수 있다. . C. Evaluation . Evaluation 단계는 연구자들 또는 의사들의 영역이라고 할 수 있다. 즉, 결과물로 나온 SNP가 의미가 있는 SNP인지 의미가 없는 SNP인지에 대한 판단을 수행한다. 예를 들어, 특정 역할을 하는 단백질, 이를 테면 kinase(신호 전달 체계의 핵심 역할을 하는 단백질)가 있다고 해보자. 이 단백질에 뮤테이션이 발생하여 SNP로 드러나면 해당 SNP가 단백질의 구조에 어떠한 영향을 얼마나 주는지에 대해 판단해야 한다. 즉, 뉴클레오타이드 A가 T로 변화되었고, 이로 인해 아미노산이 Lue에서 Glu으로 바뀌었다면, 해당 단백질의 activity에 영향이 있는가, 없는가를 판단해야 한다. 이를 통해 &quot;해당 SNP에 의한 특정 단백질의 활성화로 인해 암이 발생할 확률이 있다.&quot;는 식으로 시나리오를 짜볼 수 있겠다. 그러나, SNP는 한, 두 개 정도가 나오는 게 아니다. 정상 세포와 비정상(암) 세포 간 SNP, indel은 굉장히 많이 발생한다. 이로 인해 False positive들이 상당히 많이 발생할 수 있다. 이 false positive를 가려내는 것이 관건이다. 또한, SNP를 발견하여 단백질의 activity를 알아보기 위해서는 실제로 mutation을 도입한 후 클로닝하여 단백질 발현을 통해 activity 테스트를 해야한다. SNP가 한, 두 개 발생하는 것이 아니기 때문에 이 모든 경우를 전부 테스트 할 수는 없다는 한계가 있다. 따라서, 이 부분에 인공지능이 개입할 여지가 있으며 실제로 인공지능을 도입하려는 시도들이 많이 이루어지는 추세다. 인공지능을 통해 정상 세포가 암 세포로 전이될 확률 등을 알아낼 수 있다면, 의사들과 연구자들의 빠른 의사결정에 도움을 줄 수 있을 것이다. . FASTQ . FASTQ는 NGS 기계의 output으로 주어지는 데이터 파일이다. 이 파일의 생김새는 아래와 같다. FASTA 포맷과 다른 점은 &gt;기호 대신 @기호가 쓰인다는 점, :으로 필드가 나누어지는 점, 해당 시퀀스에 대한 인포메이션의 형식(FASTQ는 몇 번째 read고 어떤 플랫폼으로 시퀀싱 된 것인지에 대한 정보를 담고 있다.), 그리고 단 네 줄로만 이루어진다는 점이다. 또한, FASTA 포맷은 첫번째 줄의 시퀀스에 대한 설명 이후 뉴클레오타이드 또는 아미노산 서열만이 나열되는 데에 비해 FASTQ 포맷은 두 번째 줄에 실제 NGS를 통해 나온 서열이 위치하며, 네번째 줄에 정확도를 나타내기 위한 데이터가 나열된다. +는 optional이며, 부가적인 다른 인포메이션을 적을 수 있다. . accuracy . A라고 시퀀싱 된 것을 얼마나 신뢰할 수 있을까? 네 번째 줄을 보면 C로 표기된 것을 볼 수 있다. 이는 정확도를 나타내는 지표이다. 네 번째 줄의 각 알파벳을 아스키 코드로 바꾼 후 -33을 더하면 phred quality score가 나오게 된다. . 아스키 코드 American Standard Code Information Interchange 영어 알파벳 a-z, 외 특수 기호들에 대하여 컴퓨터가 인식 가능하도록 숫자로 바뀐, 코드화 된 것을 말함 A: 65, B: 66, C: 67, ... | . 네 번째 줄의 B를 예로 들자. B의 아스키 코드는 66이다. phred quality score는 -33을 한 값인 -33. 이때 quality score가 30이면 accuracy는 9가 3개인 99.9%를 의미한다 (40이면 99.99%, 50이면 99.999%). -33이므로, 99.9% 이상을 의미한다. 당연하게도 아스키 코드 값이 높아질수록 quality score가 높아진다고 이해할 수 있다. . paired-end (PE) reads . Illumina NGS 플랫폼에서 만들어진 read는 paired-end (PE) 형태이다. 즉, 하나의 서열을 양 옆에서 읽어들이는 방식이다. 이 때의 서열은 다음과 같다. forward(left) 방향으로 읽은 서열엔 1, backward(right) 방향으로 읽은 서열엔 2가 마킹된 것을 볼 수 있다. 상황과 목적에 따라 1로 마킹된 것들만 묶어서 하나의 파일로, 2로 마킹된 것들만 묶어서 하나의 파일로, 또는 1과 2 둘다 모두 들어있는 파일로 만들어 활용할 수 있다. . Data Cleanup: trimmomatic.jar . data cleanup 단계에서 raw data를 cleanup하라는 명령이다. trimmomatic.jar라는 자바 프로그램을 이용한다. . Reference . https://biohpc.cornell.edu/lab/doc/Variant_workshop_Part1.pdf | https://3months.tistory.com/234 | http://www.incodom.kr/GATK/VariantCalling | .",
            "url": "https://tfedohk.github.io/dohk/2020/09/11/NGS_%EC%9D%91%EC%9A%A9-Variant_Calling.html",
            "relUrl": "/2020/09/11/NGS_%EC%9D%91%EC%9A%A9-Variant_Calling.html",
            "date": " • Sep 11, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "fastcore: An Underrated Python Library",
            "content": ". Background . I recently embarked on a journey to sharpen my python skills: I wanted to learn advanced patterns, idioms, and techniques. I started with reading books on advanced Python, however, the information didn&#39;t seem to stick without having somewhere to apply it. I also wanted the ability to ask questions from an expert while I was learning -- which is an arrangement that is hard to find! That&#39;s when it occurred to me: What if I could find an open source project that has fairly advanced python code and write documentation and tests? I made a bet that if I did this it would force me to learn everything very deeply, and the maintainers would be appreciative of my work and be willing to answer my questions. . And that&#39;s exactly what I did over the past month! I&#39;m pleased to report that it has been the most efficient learning experience I&#39;ve ever experienced. I&#39;ve discovered that writing documentation forced me to deeply understand not just what the code does but also why the code works the way it does, and to explore edge cases while writing tests. Most importantly, I was able to ask questions when I was stuck, and maintainers were willing to devote extra time knowing that their mentorship was in service of making their code more accessible! It turns out the library I choose, fastcore is some of the most fascinating Python I have ever encountered as its purpose and goals are fairly unique. . For the uninitiated, fastcore is a library on top of which many fast.ai projects are built on. Most importantly, fastcore extends the python programming language and strives to eliminate boilerplate and add useful functionality for common tasks. In this blog post, I&#39;m going to highlight some of my favorite tools that fastcore provides, rather than sharing what I learned about python. My goal is to pique your interest in this library, and hopefully motivate you to check out the documentation after you are done to learn more! . Why fastcore is interesting . Get exposed to ideas from other languages without leaving python: I’ve always heard that it is beneficial to learn other languages in order to become a better programmer. From a pragmatic point of view, I’ve found it difficult to learn other languages because I could never use them at work. Fastcore extends python to include patterns found in languages as diverse as Julia, Ruby and Haskell. Now that I understand these tools I am motivated to learn other languages. | You get a new set of pragmatic tools: fastcore includes utilities that will allow you to write more concise expressive code, and perhaps solve new problems. | Learn more about the Python programming language: Because fastcore extends the python programming language, many advanced concepts are exposed during the process. For the motivated, this is a great way to see how many of the internals of python work. | A whirlwind tour through fastcore . Here are some things you can do with fastcore that immediately caught my attention. . . Making **kwargs transparent . Whenever I see a function that has the argument **kwargs, I cringe a little. This is because it means the API is obfuscated and I have to read the source code to figure out what valid parameters might be. Consider the below example: . def baz(a, b=2, c =3, d=4): return a + b + c def foo(c, a, **kwargs): return c + baz(a, **kwargs) inspect.signature(foo) . &lt;Signature (c, a, **kwargs)&gt; . Without reading the source code, it might be hard for me to know that foo also accepts and additional parameters b and d. We can fix this with delegates: . def baz(a, b=2, c =3, d=4): return a + b + c @delegates(baz) # this decorator will pass down keyword arguments from baz def foo(c, a, **kwargs): return c + baz(a, **kwargs) inspect.signature(foo) . &lt;Signature (c, a, b=2, d=4)&gt; . You can customize the behavior of this decorator. For example, you can have your cake and eat it too by passing down your arguments and also keeping **kwargs: . @delegates(baz, keep=True) def foo(c, a, **kwargs): return c + baz(a, **kwargs) inspect.signature(foo) . &lt;Signature (c, a, b=2, d=4, **kwargs)&gt; . You can also exclude arguments. For example, we exclude argument d from delegation: . def basefoo(a, b=2, c =3, d=4): pass @delegates(basefoo, but= [&#39;d&#39;]) # exclude `d` def foo(c, a, **kwargs): pass inspect.signature(foo) . &lt;Signature (c, a, b=2)&gt; . You can also delegate between classes: . class BaseFoo: def __init__(self, e, c=2): pass @delegates()# since no argument was passsed here we delegate to the superclass class Foo(BaseFoo): def __init__(self, a, b=1, **kwargs): super().__init__(**kwargs) inspect.signature(Foo) . &lt;Signature (a, b=1, c=2)&gt; . For more information, read the docs on delegates. . . Avoid boilerplate when setting instance attributes . Have you ever wondered if it was possible to avoid the boilerplate involved with setting attributes in __init__? . class Test: def __init__(self, a, b ,c): self.a, self.b, self.c = a, b, c . Ouch! That was painful. Look at all the repeated variable names. Do I really have to repeat myself like this when defining a class? Not Anymore! Checkout store_attr: . class Test: def __init__(self, a, b, c): store_attr() t = Test(5,4,3) assert t.b == 4 . You can also exclude certain attributes: . class Test: def __init__(self, a, b, c): store_attr(but=[&#39;c&#39;]) t = Test(5,4,3) assert t.b == 4 assert not hasattr(t, &#39;c&#39;) . There are many more ways of customizing and using store_attr than I highlighted here. Check out the docs for more detail. . . Avoiding subclassing boilerplate . One thing I hate about python is the __super__().__init__() boilerplate associated with subclassing. For example: . class ParentClass: def __init__(self): self.some_attr = &#39;hello&#39; class ChildClass(ParentClass): def __init__(self): super().__init__() cc = ChildClass() assert cc.some_attr == &#39;hello&#39; # only accessible b/c you used super . We can avoid this boilerplate by using the metaclass PrePostInitMeta. We define a new class called NewParent that is a wrapper around the ParentClass: . class NewParent(ParentClass, metaclass=PrePostInitMeta): def __pre_init__(self, *args, **kwargs): super().__init__() class ChildClass(NewParent): def __init__(self):pass sc = ChildClass() assert sc.some_attr == &#39;hello&#39; . . Type Dispatch . Type dispatch, or Multiple dispatch, allows you to change the way a function behaves based upon the input types it receives. This is a prominent feature in some programming languages like Julia. For example, this is a conceptual example of how multiple dispatch works in Julia, returning different values depending on the input types of x and y: . collide_with(x::Asteroid, y::Asteroid) = ... # deal with asteroid hitting asteroid collide_with(x::Asteroid, y::Spaceship) = ... # deal with asteroid hitting spaceship collide_with(x::Spaceship, y::Asteroid) = ... # deal with spaceship hitting asteroid collide_with(x::Spaceship, y::Spaceship) = ... # deal with spaceship hitting spaceship . Type dispatch can be especially useful in data science, where you might allow different input types (i.e. Numpy arrays and Pandas dataframes) to a function that processes data. Type dispatch allows you to have a common API for functions that do similar tasks. . Unfortunately, Python does not support this out-of-the box. Fortunately, there is the @typedispatch decorator to the rescue. This decorator relies upon type hints in order to route inputs the correct version of the function: . @typedispatch def f(x:str, y:str): return f&#39;{x}{y}&#39; @typedispatch def f(x:np.ndarray): return x.sum() @typedispatch def f(x:int, y:int): return x+y . Below is a demonstration of type dispatch at work for the function f: . f(&#39;Hello &#39;, &#39;World!&#39;) . &#39;Hello World!&#39; . f(2,3) . 5 . f(np.array([5,5,5,5])) . 20 . There are limitations of this feature, as well as other ways of using this functionality that you can read about here. In the process of learning about typed dispatch, I also found a python library called multipledispatch made by Mathhew Rocklin (the creator of Dask). . After using this feature, I am now motivated to learn languages like Julia to discover what other paradigms I might be missing. . . A better version of functools.partial . functools.partial is a great utility that creates functions from other functions that lets you set default values. Lets take this function for example that filters a list to only contain values &gt;= val: . test_input = [1,2,3,4,5,6] def f(arr, val): &quot;Filter a list to remove any values that are less than val.&quot; return [x for x in arr if x &gt;= val] f(test_input, 3) . [3, 4, 5, 6] . You can create a new function out of this function using partial that sets the default value to 5: . filter5 = partial(f, val=5) filter5(test_input) . [5, 6] . One problem with partial is that it removes the original docstring and replaces it with a generic docstring: . filter5.__doc__ . &#39;partial(func, *args, **keywords) - new function with partial application n of the given arguments and keywords. n&#39; . fastcore.utils.partialler fixes this, and makes sure the docstring is retained such that the new API is transparent: . filter5 = partialler(f, val=5) filter5.__doc__ . &#39;Filter a list to remove any values that are less than val.&#39; . . Composition of functions . A technique that is pervasive in functional programming languages is function composition, whereby you chain a bunch of functions together to achieve some kind of result. This is especially useful when applying various data transformations. Consider a toy example where I have three functions: (1) Removes elements of a list less than 5 (from the prior section) (2) adds 2 to each number (3) sums all the numbers: . def add(arr, val): return [x + val for x in arr] def arrsum(arr): return sum(arr) # See the previous section on partialler add2 = partialler(add, val=2) transform = compose(filter5, add2, arrsum) transform([1,2,3,4,5,6]) . 15 . But why is this useful? You might me thinking, I can accomplish the same thing with: . arrsum(add2(filter5([1,2,3,4,5,6]))) . You are not wrong! However, composition gives you a convenient interface in case you want to do something like the following: . def fit(x, transforms:list): &quot;fit a model after performing transformations&quot; x = compose(*transforms)(x) y = [np.mean(x)] * len(x) # its a dumb model. Don&#39;t judge me return y # filters out elements &lt; 5, adds 2, then predicts the mean fit(x=[1,2,3,4,5,6], transforms=[filter5, add2]) . [7.5, 7.5] . For more information about compose, read the docs. . . A more useful __repr__ . In python, __repr__ helps you get information about an object for logging and debugging. Below is what you get by default when you define a new class. (Note: we are using store_attr, which was discussed earlier). . class Test: def __init__(self, a, b=2, c=3): store_attr() # `store_attr` was discussed previously Test(1) . &lt;__main__.Test at 0x7fe0ab662790&gt; . We can use basic_repr to quickly give us a more sensible default: . class Test: def __init__(self, a, b=2, c=3): store_attr() __repr__ = basic_repr(&#39;a,b,c&#39;) Test(2) . Test(a=2, b=2, c=3) . . Monkey Patching With A Decorator . It can be convenient to monkey patch with a decorator, which is especially helpful when you want to patch an external library you are importing. We can use the decorator @patch from fastcore.foundation along with type hints like so: . class MyClass(int): pass @patch def func(self:MyClass, a): return self+a mc = MyClass(3) . Now, MyClass has an additional method named func: . mc.func(10) . 13 . Still not convinced? I&#39;ll show you another example of this kind of patching in the next section. . . A better pathlib.Path . When you see these extensions to pathlib.path you won&#39;t ever use vanilla pathlib again! A number of additional methods have been added to pathlib, such as: . Path.readlines: same as with open(&#39;somefile&#39;, &#39;r&#39;) as f: f.readlines() | Path.read: same as with open(&#39;somefile&#39;, &#39;r&#39;) as f: f.read() | Path.save: saves file as pickle | Path.load: loads pickle file | Path.ls: shows the contents of the path as a list. | etc. | . Read more about this here. Here is a demonstration of ls: . from pathlib import Path p = Path(&#39;../_notebooks&#39;) p.ls() # you don&#39;t get this with vanilla Pathlib.Path!! . (#21) [Path(&#39;../_notebooks/gpt2_simple_mask.jpg&#39;),Path(&#39;../_notebooks/bert_mac_small.jpg&#39;),Path(&#39;../_notebooks/causal_with_prefix.jpg&#39;),Path(&#39;../_notebooks/.DS_Store&#39;),Path(&#39;../_notebooks/2020-03-07-How_to_Create_an_Automatic_Code_Comment_Generator_using_Deep_Learning.ipynb&#39;),Path(&#39;../_notebooks/2020-09-01-fastcore.ipynb&#39;),Path(&#39;../_notebooks/2020-03-07-Syntax-Highlighting.ipynb&#39;),Path(&#39;../_notebooks/2020-03-06-bart.ipynb&#39;),Path(&#39;../_notebooks/README.md&#39;),Path(&#39;../_notebooks/2020-05-01-TrainDonkeyCar.ipynb&#39;)...] . Wait! What&#39;s going on here? We just imported pathlib.Path - why are we getting this new functionality? Thats because we imported the fastcore.foundation module, which patches this module via the @patch decorator discussed earlier. Just to drive the point home on why the @patch decorator is useful, I&#39;ll go ahead and add another method to Path right now: . @patch def fun(self:Path): return &quot;This is fun!&quot; p.fun() . &#39;This is fun!&#39; . That is magical, right? I know! That&#39;s why I&#39;m writing about it! . . An Even More Concise Way To Create Lambdas . Self, with an uppercase S, is an even more concise way to create lambdas that are calling methods on an object. For example, let&#39;s create a lambda for taking the sum of a Numpy array: . arr=np.array([5,4,3,2,1]) f = lambda a: a.sum() assert f(arr) == 15 . You can use Self in the same way: . f = Self.sum() assert f(arr) == 15 . Let&#39;s create a lambda that does a groupby and max of a Pandas dataframe: . import pandas as pd df=pd.DataFrame({&#39;Some Column&#39;: [&#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;b&#39;, ], &#39;Another Column&#39;: [5, 7, 50, 70]}) f = Self.groupby(&#39;Some Column&#39;).mean() f(df) . Another Column . Some Column . a 6 | . b 60 | . Read more about Self in the docs). . . Notebook Functions . These are simple but handy, and allow you to know whether or not code is executing in a Jupyter Notebook, Colab, or an Ipython Shell: . in_notebook(), in_colab(), in_ipython() . (True, False, True) . This is useful if you are displaying certain types of visualizations, progress bars or animations in your code that you may want to modify or toggle depending on the environment. . . A Drop-In Replacement For List . You might be pretty happy with Python&#39;s list. This is one of those situations that you don&#39;t know you needed a better list until someone showed one to you. Enter L, a list like object with many extra goodies. . The best way I can describe L is to pretend that list and numpy had a pretty baby: . define a list (check out the nice __repr__ that shows the length of the list!) . L(1,2,3) . (#3) [1,2,3] . Shuffle a list: . p = L.range(20).shuffle() p . (#20) [2,0,18,6,15,17,14,8,12,1...] . Index into a list: . p[2,4,6] . (#3) [18,15,14] . L has sensible defaults, for example appending an element to a list: . 1 + L(2,3,4) . (#4) [1,2,3,4] . There is much more L has to offer. Read the docs to learn more. . But Wait ... There&#39;s More! . There are more things I would like to show you about fastcore, but there is no way they would reasonably fit into a blog post. Here is a list of some of my favorite things that I didn&#39;t demo in this blog post: . Utilities . The Utilites section contain many shortcuts to perform common tasks or provide an additional interface to what standard python provides. . mk_class: quickly add a bunch of attributes to a class | wrap_class: add new methods to a class with a simple decorator | groupby: similar to Scala&#39;s groupby | merge: merge dicts | fasttuple: a tuple on steroids | Infinite Lists: useful for padding and testing | chunked: for batching and organizing stuff | . Multiprocessing . The Multiprocessing section extends python&#39;s multiprocessing library by offering features like: . progress bars | ability to pause to mitigate race conditions with external services | processing things in batches on each worker, ex: if you have a vectorized operation to perform in chunks | . Functional Programming . The functional programming section is my favorite part of this library. . maps: a map that also composes functions | mapped: A more robust map | using_attr: compose a function that operates on an attribute | . Transforms . Transforms is a collection of utilities for creating data transformations and associated pipelines. These transformation utilities build upon many of the building blocks discussed in this blog post. . Further Reading . It should be noted that you should read the main page of the docs first, followed by the section on tests to fully understand the documentation. . The fastcore documentation site. | The fastcore GitHub repo. | Blog post on delegation. | . Shameless plug: fastpages . This blog post was written entirely in a Jupyter Notebook, which GitHub automatically converted into to a blog post! Sound interesting? Check out fastpages. .",
            "url": "https://tfedohk.github.io/dohk/fastcore/",
            "relUrl": "/fastcore/",
            "date": " • Sep 1, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://tfedohk.github.io/dohk/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://tfedohk.github.io/dohk/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "저는 대전 소재의 한국과학기술정보연구원(KISTI)의 과학데이터분석연구실에서 기상 데이터를 분석하는 연구에 참여연구원으로 일한 경력이 있습니다. 이때 처음으로 인공지능의 기술 분야 중 하나인 머신러닝을 접하였고 머신러닝을 혼자 공부해 나가면서 재미있는 분야라 생각하였습니다. 특히, 이때 얻은 귀중한 점 두 가지는 첫째로 머신러닝에서 핵심적으로 쓰이는 gradient descent를 수학적인 배경지식 이해부터 알고리즘 구현까지 스스로 해내었다는 점, 둘째로 학부에서 배웠던 수학이 실제로 눈앞에서 활용되는 모습을 통해 수학의 중요성과 수학 공부의 즐거움을 느꼈다는 점입니다. 이후 저는 관련 공부를 더 이어가고자 하였고, 모교의 대학원에 진학하여 딥러닝과 강화학습을 이용하여 다양한 프로젝트를 진행했습니다. (제가 진행했던 프로젝트에 대한 결과물은 이력의 첨부영역에 있습니다.) . 제가 인공지능 분야를 공부하면서 느낀 점은 인공지능은 결국 도구에 불과하다는 점입니다. 즉, 어떤 도메인에 인공지능을 적용하여 가치를 창출할지에 대한, 일종의 가치 판단의 문제가 생기게 됩니다. 저는 석사 수료 상태로 잠시 진로를 돌아보는 와중에 바이오인포매틱스 분야를 접하게 되었고, BT에 IT를 접목하고 싶다는 생각을 가지게 되었습니다. . 관심분야 . 인공지능(Artificial Intelligence; 머신러닝(ML), 딥러닝(DL), 강화학습(RL)) 생명정보학(Bioinformatics) . 이력 . 2012.03 ~ 2017.08 &gt; 한국기술교육대학교 컴퓨터공학부 학사 과정 | 2016.01 ~ 2016.06 &gt; 한국과학기술정보연구원(KISTI) 대전 본원 참여연구원 | 2017.09 ~ 2019.08 &gt; 한국기술교육대학교 창의융합공학협동과정 ICT융합 석사 과정 | 2018.07 ~ 2020.08 &gt; 한국기술교육대학교 능력교육개발원 보조강사 | 2019.09 ~ 2019.12 &gt; 대한상공회의소 충북인력개발원 시간강사 | 2020.03 ~ &gt; 성남 폴리텍대학 하이테크 생명정보시스템 과정 | . 학력사항 . 2012.03 ~ 2017.08 &gt; 한국기술교육대학교 컴퓨터공학부(CSE) 학사 졸업 총 이수 학점: 156 | 총 학점: 3.4 / 4.5 | 전공 학점: 3.32 / 4.5 | . | 2017.09 ~ 2019.08 &gt; 한국기술교육대학교 창의융합공학협동과정 ICT융합 석사 수료 총 이수 학점: 30 | 총 학점: 4.5 / 4.5 | 작성 논문: [첨부1] | . | . 경력 및 대외활동 . 2020.03.01 ~ &gt; 성남 폴리텍대학 하이테크 생명정보시스템 과정 | 2019.09.23 ~ 2019.12.17 &gt; 대한상공회의소 충북인력개발원 시간강사 | 부서: 전기시스템제어 | 과정명: PLC전문가과정 | 교과목명: 펌웨어프로그래밍실무 | . | 2018.07 ~ 2020.08 &gt; 한국기술교육대학교 능력교육개발원 보조강사 (Assistant Instructor) | 담당 과목: [첨부2] | . | 2016.01.01 ~ 2016.06.30 &gt; 한국과학기술정보연구원(KISTI) 대전 본원 참여연구원/학생연구원 (Graduate Student Research Assistant) | 부서: 과학데이터분석연구실 | 주요업무: 데이터 분석 | . | . 자격증 . 워드프로세서 1급 / 대한상공회의소 / 2005.10.21 | 운전면허 1종 / 대전지방경찰청 / 2016.08.05 | 정보처리기사 / 한국산업인력공단 / 2017.05.26 | 훈련교사자격증 3급 1호 / 고용노동부 / 2019.07.26 정보기술개발 | 통신서비스 | 전자기기개발 | 전자기기일반 | . | . [첨부1] . 한국기술교육대학교 창의융합공학협동과정 석사 과정 작성 논문 . “Time Series Classification of Cryptocurrency Price Trend Based on a Recurrent LSTM Neural Network, “ JIPS(Journal of Information Processing Systems), Volume: 15, No: 3, Page: 694 ~ 706, Year: 2019, 10.3745/JIPS.03.0120 / 1저자 | “Unity 3D 기반 다중 에이전트 강화학습 환경 구현, “ 2019.06, 한국통신학회 | **“분산 A3C를 활용한 회전식 도립 진자 시스템 설계, “ 한국정보처리학회, VOL 26 NO. 01 PP. 0493 ~ 0495 2019. 05 / 1저자 | “Deep Q-Network Based Rotary Inverted Pendulum System and Its Monitoring on the EdgeX Platform, “, IEEE Access, 2019.02 / https://ieeexplore.ieee.org/document/8668979 / 2저자 | “A3C를 활용한 블록체인 기반 금융 자산 포트폴리오 관리, “ 2019.01, 한국정보처리학회 | “EdgeX Foundry 기반의 IoT 제어 시스템 구현, “ 한국정보처리학회, VOL 25 NO. 02 PP. 0995 ~ 0997 2018.11 / 1저자 | “강화학습을 이용한 회전식 도립전자 시스템 설계, “, 한국정보처리학회, VOL 25 NO. 02 PP. 0705 ~ 0707 2018. 11 / 2저자 | “그래디언트 부스팅을 활용한 암호화폐 가격동향 예측, “ 정보처리학회논문지, 2018.10 / 2저자 | “암호화폐 가격 정보 데이터에 대한 상관관계분석 및 회귀테스트, “ 한국정보처리학회, VOL 25 NO. 01 PP. 0346 ~ 0349 2018. 05 / 1저자 / 우수논문상 수상 | “Recurrent Neural Network을 이용한 플로우 기반 네트워크 트래픽 분류, “, 2017.07, 한국정보처리학회 | . [첨부2] . 한국기술교육대학교 능력교육개발원 보조강사 담당 과목 . 20.08.10 - 20.08.14 &gt; 데이터 마이닝과 빅데이터 분석 기초 및 응용 | 20.08.03 - 20.08.07 &gt; PyTorch와 Azure로 함께 도전하는 인공지능 입문 | 20.06.06 - 20.06.07 &gt; 엑셀을 활용한 빅데이터 분석 기초 | 20.05.23 - 20.05.24 &gt; 융합기술 기반 SW개발자를 위한 웹 프로그래밍 1 | 20.01.20 - 20.01.21 &gt; Python 프로그래밍 기초 | 20.01.13 - 20.01.17 &gt; Keras 코딩 하며 배우는 생성적 적대 신경망(GAN) 입문 | 19.12.30 - 20.01.03 &gt; Azure와 Keras로 함께 풀어보는 인공지능 실전 프로젝트 | 19.12.21 - 19.12.22 &gt; Excel BI를 이용한 빅데이터 가공 기초 | 19.11.30 - 19.12.01 &gt; IT시스템 통합운영 및 시스템 유지보수 관리 | 19.11.23 - 19.11.24 &gt; Excel BI를 이용한 빅데이터 가공 기초 | 19.08.12 - 19.08.16 &gt; Power BI를 활용한 빅데이터 분석과 시각화 | 19.08.05 - 19.08.09 &gt; 텐서플로우로 풀어보는 6가지 중급 인공지능 프로젝트 | 19.07.29 - 19.08.02 &gt; 사물인터넷 구현을 위한 아두이노 기초 실습 | 19.07.22 - 19.07.26 &gt; 엑셀로 배우는 빅데이터 분석 이론 및 실습 | 19.06.29 - 19.06.30 &gt; 딥러닝을 활용한 자연어 처리 | 19.06.08 - 19.06.09 &gt; Linux 기초와 Apache Hadoop설치 | 19.05.25 - 19.05.26 &gt; PYTHON 프로그래밍 기본 | 19.01.14 - 19.01.18 &gt; 텐서플로우로 익히는 딥러닝 이론과 구현 | 18.07.23 - 18.07.27 &gt; 머신 러닝 기술의 이해 및 실습 | . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://tfedohk.github.io/dohk/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://tfedohk.github.io/dohk/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}